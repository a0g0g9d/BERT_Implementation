{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cb71525",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b67954f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"glue\", \"cola\")\n",
    "dataset = dataset[\"train\"]  # Just take the training split for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d2dfcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8551, 3)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d92a8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dataset[8001:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8008bdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[:8000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0746d063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': \"Our friends won't buy this analysis, let alone the next one we propose.\", 'label': 1, 'idx': 0}\n",
      "{'sentence': \"One more pseudo generalization and I'm giving up.\", 'label': 1, 'idx': 1}\n",
      "{'sentence': \"One more pseudo generalization or I'm giving up.\", 'label': 1, 'idx': 2}\n",
      "{'sentence': 'The more we study verbs, the crazier they get.', 'label': 1, 'idx': 3}\n",
      "{'sentence': 'Day by day the facts are getting murkier.', 'label': 1, 'idx': 4}\n",
      "{'sentence': \"I'll fix you a drink.\", 'label': 1, 'idx': 5}\n",
      "{'sentence': 'Fred watered the plants flat.', 'label': 1, 'idx': 6}\n",
      "{'sentence': 'Bill coughed his way out of the restaurant.', 'label': 1, 'idx': 7}\n",
      "{'sentence': \"We're dancing the night away.\", 'label': 1, 'idx': 8}\n",
      "{'sentence': 'Herman hammered the metal flat.', 'label': 1, 'idx': 9}\n",
      "{'sentence': 'The critics laughed the play off the stage.', 'label': 1, 'idx': 10}\n",
      "{'sentence': 'The pond froze solid.', 'label': 1, 'idx': 11}\n",
      "{'sentence': 'Bill rolled out of the room.', 'label': 1, 'idx': 12}\n",
      "{'sentence': 'The gardener watered the flowers flat.', 'label': 1, 'idx': 13}\n",
      "{'sentence': 'The gardener watered the flowers.', 'label': 1, 'idx': 14}\n",
      "{'sentence': 'Bill broke the bathtub into pieces.', 'label': 1, 'idx': 15}\n",
      "{'sentence': 'Bill broke the bathtub.', 'label': 1, 'idx': 16}\n",
      "{'sentence': 'They drank the pub dry.', 'label': 1, 'idx': 17}\n",
      "{'sentence': 'They drank the pub.', 'label': 0, 'idx': 18}\n",
      "{'sentence': 'The professor talked us into a stupor.', 'label': 1, 'idx': 19}\n",
      "{'sentence': 'The professor talked us.', 'label': 0, 'idx': 20}\n",
      "{'sentence': 'We yelled ourselves hoarse.', 'label': 1, 'idx': 21}\n",
      "{'sentence': 'We yelled ourselves.', 'label': 0, 'idx': 22}\n",
      "{'sentence': 'We yelled Harry hoarse.', 'label': 0, 'idx': 23}\n",
      "{'sentence': 'Harry coughed himself into a fit.', 'label': 1, 'idx': 24}\n",
      "{'sentence': 'Harry coughed himself.', 'label': 0, 'idx': 25}\n",
      "{'sentence': 'Harry coughed us into a fit.', 'label': 0, 'idx': 26}\n",
      "{'sentence': 'Bill followed the road into the forest.', 'label': 1, 'idx': 27}\n",
      "{'sentence': 'We drove Highway 5 from SD to SF.', 'label': 1, 'idx': 28}\n",
      "{'sentence': 'Fred tracked the leak to its source.', 'label': 1, 'idx': 29}\n",
      "{'sentence': 'John danced waltzes across the room.', 'label': 1, 'idx': 30}\n",
      "{'sentence': 'Bill urinated out the window.', 'label': 1, 'idx': 31}\n",
      "{'sentence': 'Bill coughed out the window.', 'label': 1, 'idx': 32}\n",
      "{'sentence': 'Bill bled on the floor.', 'label': 1, 'idx': 33}\n",
      "{'sentence': 'The toilet leaked through the floor into the kitchen below.', 'label': 1, 'idx': 34}\n",
      "{'sentence': 'Bill ate off the floor.', 'label': 1, 'idx': 35}\n",
      "{'sentence': 'Bill drank from the hose.', 'label': 1, 'idx': 36}\n",
      "{'sentence': 'This metal hammers flat easily.', 'label': 1, 'idx': 37}\n",
      "{'sentence': 'They made him president.', 'label': 1, 'idx': 38}\n",
      "{'sentence': 'They made him angry.', 'label': 1, 'idx': 39}\n",
      "{'sentence': 'They caused him to become angry by making him.', 'label': 0, 'idx': 40}\n",
      "{'sentence': 'They caused him to become president by making him.', 'label': 0, 'idx': 41}\n",
      "{'sentence': 'They made him to exhaustion.', 'label': 0, 'idx': 42}\n",
      "{'sentence': 'They made him into a monster.', 'label': 1, 'idx': 43}\n",
      "{'sentence': 'The trolley rumbled through the tunnel.', 'label': 1, 'idx': 44}\n",
      "{'sentence': 'The wagon rumbled down the road.', 'label': 1, 'idx': 45}\n",
      "{'sentence': 'The bullets whistled past the house.', 'label': 1, 'idx': 46}\n",
      "{'sentence': 'The knee replacement candidate groaned up the stairs.', 'label': 1, 'idx': 47}\n",
      "{'sentence': 'The car honked down the road.', 'label': 0, 'idx': 48}\n",
      "{'sentence': 'The dog barked out of the room.', 'label': 0, 'idx': 49}\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    print(dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "022937a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "## treat 3letters as a single token\n",
    "tokenized_data = tokenizer(train_dataset[\"sentence\"], return_tensors=\"np\", padding=True)\n",
    "# Tokenizer returns a BatchEncoding, but we convert that to a dict for Keras\n",
    "tokenized_data = dict(tokenized_data)\n",
    "\n",
    "labels = np.array(train_dataset[\"label\"])  # Label is already an array of 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88ee2ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import TFAutoModelForSequenceClassification\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# # Load and compile our model\n",
    "# model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\")\n",
    "# # Lower learning rates are often better for fine-tuning transformers\n",
    "# model.compile(optimizer=Adam(3e-5))  # No loss argument!\n",
    "\n",
    "# model.fit(tokenized_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3a7edc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load and compile our model\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ba99ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108310272 \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,311,810\n",
      "Trainable params: 108,311,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82ad71e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids\n",
      "token_type_ids\n",
      "attention_mask\n"
     ]
    }
   ],
   "source": [
    "for key,val in tokenized_data.items():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9c6fcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 47)\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_data['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e076f4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 47)\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_data['token_type_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a8e622f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 47)\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_data['attention_mask'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cc9053e",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ff135df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': 'I read three his books.', 'label': 0, 'idx': 1000}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f57845da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 101  146 2373 1210 1117 2146  119  102    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_data['input_ids'][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "988c5b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_data['token_type_ids'][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ce88982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_data['attention_mask'][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d655c7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split( tokenized_data , labels , test_size= 0.15, random_state=42 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe8d9dd",
   "metadata": {},
   "source": [
    "##### Simple train test split is not  working because tokenization is a dictionary and it only works for arrays, so we have to split all the 3 keys of dictionary into separatae lists and merge them once the work is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33a24eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenized_data['input_ids']\n",
    "token_type_ids = tokenized_data['token_type_ids']\n",
    "attention_mask = tokenized_data['attention_mask']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train1, X_test1, Y_train1, Y_test1 = train_test_split( input_ids , labels , test_size= 0.15, random_state=42 )\n",
    "X_train2, X_test2, Y_train2, Y_test2 = train_test_split( token_type_ids , labels , test_size= 0.15, random_state=42 )\n",
    "X_train3, X_test3, Y_train3, Y_test3 = train_test_split( attention_mask , labels , test_size= 0.15, random_state=42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3458935",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = dict()\n",
    "td['input_ids'] = X_train1\n",
    "td['token_type_ids'] = X_train2\n",
    "td['attention_mask'] = X_train3\n",
    "test_td = dict()\n",
    "test_td['input_ids'] = X_test1\n",
    "test_td['token_type_ids'] = X_test2\n",
    "test_td['attention_mask'] = X_test3\n",
    "td_labels = Y_train1\n",
    "td_test_labels = Y_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e589cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6800\n",
      "1200\n",
      "6800\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "print(len(td['input_ids']))\n",
    "print(len(test_td['input_ids']))\n",
    "print(len(td_labels))\n",
    "print(len(td_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "056e4f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "170/170 [==============================] - ETA: 0s - loss: 1.4363 - accuracy: 0.6835\n",
      "Epoch 1: saving model to Bert.tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Bert.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Bert.tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 107s 569ms/step - loss: 1.4363 - accuracy: 0.6835 - val_loss: 0.6931 - val_accuracy: 0.7110\n",
      "Epoch 2/12\n",
      "170/170 [==============================] - ETA: 0s - loss: 0.7345 - accuracy: 0.6770\n",
      "Epoch 2: saving model to Bert.tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Bert.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Bert.tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 108s 636ms/step - loss: 0.7345 - accuracy: 0.6770 - val_loss: 0.6931 - val_accuracy: 0.7110\n",
      "Epoch 3/12\n",
      "170/170 [==============================] - ETA: 0s - loss: 0.7207 - accuracy: 0.6710\n",
      "Epoch 3: saving model to Bert.tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Bert.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Bert.tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 106s 625ms/step - loss: 0.7207 - accuracy: 0.6710 - val_loss: 0.6931 - val_accuracy: 0.7110\n",
      "Epoch 4/12\n",
      "170/170 [==============================] - ETA: 0s - loss: 0.7073 - accuracy: 0.6691\n",
      "Epoch 4: saving model to Bert.tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Bert.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Bert.tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 104s 610ms/step - loss: 0.7073 - accuracy: 0.6691 - val_loss: 0.6931 - val_accuracy: 0.7110\n",
      "Epoch 5/12\n",
      "170/170 [==============================] - ETA: 0s - loss: 0.7004 - accuracy: 0.6708\n",
      "Epoch 5: saving model to Bert.tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Bert.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Bert.tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 91s 537ms/step - loss: 0.7004 - accuracy: 0.6708 - val_loss: 0.6931 - val_accuracy: 0.7110\n",
      "Epoch 6/12\n",
      "170/170 [==============================] - ETA: 0s - loss: 0.7003 - accuracy: 0.6825\n",
      "Epoch 6: saving model to Bert.tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Bert.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Bert.tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 92s 544ms/step - loss: 0.7003 - accuracy: 0.6825 - val_loss: 0.6931 - val_accuracy: 0.7110\n",
      "Epoch 7/12\n",
      "170/170 [==============================] - ETA: 0s - loss: 0.7010 - accuracy: 0.6756\n",
      "Epoch 7: saving model to Bert.tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Bert.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Bert.tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 92s 543ms/step - loss: 0.7010 - accuracy: 0.6756 - val_loss: 0.6931 - val_accuracy: 0.7110\n",
      "Epoch 8/12\n",
      "170/170 [==============================] - ETA: 0s - loss: 0.6994 - accuracy: 0.6717\n",
      "Epoch 8: saving model to Bert.tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Bert.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Bert.tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 93s 549ms/step - loss: 0.6994 - accuracy: 0.6717 - val_loss: 0.6931 - val_accuracy: 0.7110\n",
      "Epoch 9/12\n",
      "170/170 [==============================] - ETA: 0s - loss: 0.6960 - accuracy: 0.6693\n",
      "Epoch 9: saving model to Bert.tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Bert.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Bert.tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 92s 541ms/step - loss: 0.6960 - accuracy: 0.6693 - val_loss: 0.6931 - val_accuracy: 0.7110\n",
      "Epoch 10/12\n",
      "170/170 [==============================] - ETA: 0s - loss: 0.6963 - accuracy: 0.6660\n",
      "Epoch 10: saving model to Bert.tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Bert.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Bert.tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 92s 541ms/step - loss: 0.6963 - accuracy: 0.6660 - val_loss: 0.6931 - val_accuracy: 0.7110\n",
      "Epoch 11/12\n",
      "170/170 [==============================] - ETA: 0s - loss: 0.6960 - accuracy: 0.6634\n",
      "Epoch 11: saving model to Bert.tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Bert.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Bert.tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 108s 637ms/step - loss: 0.6960 - accuracy: 0.6634 - val_loss: 0.6931 - val_accuracy: 0.7110\n",
      "Epoch 12/12\n",
      "170/170 [==============================] - ETA: 0s - loss: 0.6948 - accuracy: 0.6507\n",
      "Epoch 12: saving model to Bert.tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Bert.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Bert.tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "170/170 [==============================] - 123s 725ms/step - loss: 0.6948 - accuracy: 0.6507 - val_loss: 0.6931 - val_accuracy: 0.7110\n"
     ]
    }
   ],
   "source": [
    "### I am training the model using my own script\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "start = time.time()\n",
    "callback = tf.keras.callbacks.ModelCheckpoint(filepath='Bert.tf',\n",
    "                                                  monitor='val_acc', mode='max',\n",
    "                                                 verbose=1)\n",
    "opt = Adam(learning_rate=0.000001)\n",
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "             optimizer = opt,\n",
    "              metrics = ['accuracy'])\n",
    "history = model.fit(td,\n",
    "                    td_labels,\n",
    "                    validation_split=0.2,\n",
    "                    batch_size = 32,\n",
    "                    epochs = 12,\n",
    "                    callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7249b6f",
   "metadata": {},
   "source": [
    "##### Testing (Inference)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "090b6c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence [\"Evan's every idea was completely insane.\", 'Sally is making scones, and Gillian is too.', 'Everyone claimed that the poison was neutralized.', 'Jonathan persuaded Kate to lick himself.', 'That Jason arrived infuriated Medea.', 'Medea was happy, because she had got the highest marks', 'Keep yourself clean!', 'Cassandra has foretold disaster again.', \"Bill's reading of Shakespeare satisfied me\", 'Who poisoned who?', 'Pigs love truffles.', 'Owners of pigs love truffles', 'So quickly did the vampire move, that we barely saw him.', 'Humans love to eat those pigs.', 'She has kissed she.', 'Jason intended for he to learn magic.', 'Jason persuaded Medea to be treated by the doctor', 'It is true that I might be doing something other than going to the party.', 'Jason expected Medea to be treated by the doctor', 'I found there.', 'Moya said she liked football.', 'Anson became the Mayor', 'Kane ate dirt.', 'Benjamin gave the cloak to Nathan', 'The fig chuckled', 'Poseidon had run away, because the executioner murdered Hera.', 'A description of Aristotle is in the book.', 'Julie and Jenny did.', \"It's quarter past four.\", 'Owners of a pig love to eat truffles.', 'That whether the world is round is unknown bothered Athena.', 'No one expected Agamemnon to to win', \"Euclid was interested in Plato's description of geometry.\", 'Every reading Shakespeare satisfied me', 'Can will he do it?', 'Medea poisoned who?', 'He looked up it', 'who guy did you see.', 'We kicked myself', 'Who would Poseidon run away, if the executioner murdered?', 'Anson kissed him', 'which city the claim that Philip would invade.', \"I haven't left yet\", 'I am eating a mango and Gillian has too.', 'letter is on the table', 'Who ate the cake?', 'Why did you say that you were leaving?', 'Michael left Meg', 'Aphrodite quickly may free the animals', 'The reading of Shakespeare satisfied me', 'The weather rained', 'Gilgamesh seek may Ishtar', 'No one expected to win.', 'Who did that Plato loved seem to be known by everyone.', 'The bear sniffs', 'It hung on the wall.', 'Jason killed.', 'Many people were there playing on the beach', 'Know yourself!', 'Agamemnon attempted to behave well.', 'Julie felt he was there', 'He thought that Dracula was the Prince of Darkness.', 'I have eaten already', 'It is not true that I have left yet.', 'That monkeys is eating the banana.', 'I could have been flying helicopters by now.', 'Anson put a book', 'Gilgamesh might have not been reading the cuneiform tablets.', 'I asked if Medea poisoned Jason.', 'Who did you persuade to go?', 'What did you get all for Xmas?', 'Some disgruntled old pigs in those ditches love truffles', 'Jason was killed.', 'I would like to might do it', 'Peter is some disgruntled old pigs in those ditches.', 'There was him in the garden.', 'Gilgamesh is in the dungeon.', 'Anson will come to the party.', 'Gilgamesh has never flown a dragon.', 'Julie maintained her own questions over the course of the argument.', 'His analysis, I never liked.', 'That bottle of water might.', 'Did Medea poison who?', 'She took a picture of the phoenix', 'Look after herself!', 'Who did Medea poison?', 'I tried for to get them.', 'Who did you introduce Athena to?', 'Can I keep the screwdriver just like a carpenter keep the screwdriver?', 'Jason refrained from casting the spell', 'Andrew likes lard on his sandwiches', 'Who seemed to have left first?', 'Ron asked that the potion was ready', 'Hierarchy of Projections:', 'We decided to paint the bathroom a lurid lime green colour.', 'She kicked her', 'He knows he.', 'I believed there to be three books on the subject.', 'The child wail', 'Which girl ate the cake?', 'That Plato lived in the city of Athens was well-known.', 'Collapsed Harry.', 'For you to do that would be a mistake.', 'Jason thinks who Medea had poisoned.', 'I believe she is pregnant', 'No one expected him to to win.', \"He'll no can do it, can he?\", \"Which poem did you hear Homer's recital of last night?\", 'Raffi slept well, and Gillian will too', \"He's bound to should do it\", 'It might have cracked open', 'Where did Perseus see the Gorgon?', 'The scissors are lost', 'Gilgamesh should be slowly tickling the mandrake', 'Agamemnon seems PRO to be a maniac', 'Myself saw me', 'I believed she was pregnant', 'Anson gave Fluffy to Jenny.', 'The very old and extremely wise owl.', 'Who did that Plato loved prove to be his undoing.', 'What Medea believed was Jason to be a murderer.', 'The owl hated the evil bat and loved the wise eagle.', 'No one could remove the blood on the wall', 'He can can go', 'Gillian has made pasta and David is too.', 'Jason intended for PRO to learn magic.', 'The boys should could all go', 'I assumed to be innocent', 'Anson danced extremely frantically at Trade.', 'The Gorgon is easy to believe the claim that Perseus slew.', 'She kicked itself', 'Julie became a fond of Lloyd.', \"Lee's youngest and Dawn's oldest son ran away.\", 'Anson kicked the cat', 'Merlin is extremely evil.', 'Syntax is easy to pretend that you can teach.', 'I want to eat macaroni', 'Which ode did which poet write?', 'What she thought that was the poison was neutralised', 'Who drank the poison?', 'What Medea arranged was for her children to be poisoned.', \"No one's mother had baked anything.\", 'What kind of actor is he?', 'What did she eat?', 'Frantically at, Anson danced extremely Trade', 'I have often a cold.', \"Who did Maria say that she'd kiss and kick?\", 'Where did they go all for their holidays?', 'They came running over the hill and through the woods', 'The airport yawned', 'How quickly did you eat the cake?', 'Many fish are in the sea.', 'They arrived first', 'People were playing on the beach.', 'Benjamin gave to Lee it.', 'He liked Anson.', 'The bear sniff', 'I inquired could we leave early.', 'The bears sniff', 'I persuaded there to be a problem.', 'His book', 'He looked the number up', 'Has Jenny eaten a cake?', 'Which goddess helped us?', 'Medea killed Jason.', 'Ron certainly will buy a dog.', 'They shaved David and Anson.', 'We believed to be the headmaster', 'Which king did you wonder invaded which city?', 'No one expected Agamemnon to win.', 'The day snowed', 'Gilgamesh never flies dragons.', 'Keep myself clean!', 'The dragons have all been slain.', 'Did that Medea killed her children upset Jason?', 'The amoeba coughed and then it fainted.', 'I want to sing', 'He will can go', 'Medea seemed that has poisoned Jason.', 'Having read Shakespeare satisfied me', 'Peter is owners of pigs.', 'Odysseus attempted the helmsman to hear the sirens.', 'Gilgamesh may seek Ishtar', 'The librarian likes books.', 'Alison and David soaked their feet after dinner', 'Mary is faster than John is.', 'Alison and David soaked their feet in the kitchen', 'You kicked you', 'Did you see Mary?', 'Raffi has made pasta, and David has too.', 'There seemed to be three men in the garden.', \"That Medea murdered Jason didn't surprise anyone.\", \"Moya's football team loved her\", 'I sent she away.', 'Jason persuaded Medea that she should desert her family', 'Aphrodite stinks to be omnipotent.', 'Every reading of Shakespeare satisfied me', 'Bill reading Shakespeare and Maureen singing Schubert satisfy me', 'When the executioner arrived, Poseidon was asleep', 'They kicked themselves', 'Many vampires have become vegetarian.', 'That that the world is round is obvious upset Hermes.', 'Bill not destroyed the world.', 'John saw Stephan', 'I destroyed there.', \"What was Euclid interested in Plato's description of?\", 'I like Anson', 'The dragons simply all died out.', 'Gilgamesh did not fly the dragon.', 'Which goddess might help us?', 'Humans love to eat pigs.', 'Which poem about Achilles did Homer recite?', 'The boys should all could go', 'The owl hated the evil and the wise eagle.', 'The shield that saved Achilles life.', \"Evan's every desire\", 'I wondered whether Medea had fled.', 'I have eaten my hat already', 'He will could go', 'Jenny swallowed the fly', 'The flying car hit the tree in the air', 'I have a book.', 'Jason thought of defending the dragon', 'It seems that Agamemnon is a maniac', 'Which city do you believe the claim that Philip would invade?', 'We claimed that Perseus had killed the Gorgon', 'We need some technician to help us.', 'The scissors is lost', 'I have been flying helicopters for years.', 'Sam gave the cloak to Lee and the magic chalice to Matthew.', 'We kicked us', 'No reading of Shakespeare satisfied me', 'What did he reply?', 'It was claimed that by everyone the poison was neutralised', 'I asked which city which king invaded.', 'Raffi makes pesto pasta, and David does too', 'Eat dirt!', 'Look after yourself!', 'She wanted to can leave', 'Arthur gave the tapestry to Lancelot.', 'We took the car to the town', 'Benjamin gave the cloak to Lee.', 'Not reading Shakespeare satisfied me', 'There were killed three men.', 'Gilgamesh has not been reading the cuneiform tablets', 'The imposition of the government of a fine.', 'When Alison and David soaked their feet was after dinner', \"This problem's analysis is made a lot easier when you understand differential equations.\", 'Dracula thought that himself was the Prince of Darkness.', 'Gilgamesh might have been not reading the cuneiform tablets.', 'Who asked which statue which tourist had taken a photo of?', \"Willow said that she'd kiss Tara and kick Xander.\", 'I climbed right up the tree.', 'All the dragons had escaped.', 'Who did you attempt to force Jason to kill?', 'I thought of the moon', 'Benjamin thought he would give the cloak to Lee and the cloak to Lee he gave.', 'I wondered had he left yet.', 'I thought she was pregnant', 'I arranged for him to see her.', 'It was over the hill and through the woods that they came running', 'Who did you ask saw what?', 'Gilgamesh might can seek Ishtar', 'Gilgamesh arrived', 'Jason arrived by Medea.', 'Oil spread over the sea shore.', 'What Jason asked was whether the potion was ready', 'Jason asked whether that the potion was ready', 'Have you seen Mary? I have vP seen Mary', 'It seems that Agamemnon left.', 'Those monkeys are eating the banana.', 'I introduced her to he.', 'Nathan showed to Benjamin it.', 'He kicked yourself', 'Anson tried to shave himself.', 'Gilgamesh never has flown a dragon.', 'What Julie did of Lloyd was become fond.', 'It is not allowed to incriminate oneself.', 'The analysis of the problem was flawed', 'Which goddess did help us?', 'Poseidon appears to have turned out to have left.', 'Gilgamesh has been not reading the cuneiform tablets.', 'Danced extremely, Anson frantically at Trade', 'Aphrodite wanted to live and Ishtar tried to do', 'I kicked yourself', 'How fond of Esther is Agamemnon?', 'Ron heard a discussion in the foyer', 'My mother hated myself', 'The students demonstrated the technique this morning', 'He walked up the hill.', 'We wanted to ate cake', 'Jason knew those Medea had cast the spell', 'Gilgamesh must should seek Ishtar', 'Aphrodite said he freed the animals and free the animals he did', 'Did you drink the poison?', 'Whether Agamemnon had triumphed was unknown.', 'Her has kissed her.', 'I often have a cold.', 'Jason whispered the phoenix had escaped', 'Bill reading of Shakespeare satisfied me', \"Didn't the magic work?\", 'Anson thought Julie had fainted', 'The horse fell', 'Odysseus attempted Odysseus to hear the sirens.', 'Burn letters to Peter!', 'Genie intoned the prayer', \"Gilgamesh didn't fly the broomstick.\", \"Ron's likely to be on the Web, isn't he?\", \"Bill's reading Shakespeare and Maureen's singing Schubert satisfy me\", 'Owners of a pig loves to eat truffles', 'Gilgamesh might loved Ishtar', 'Paul had an affair', 'Poseidon appears to own a dragon', 'The twins might have both been at the party.', 'That Jason had arrived was obvious infuriated Medea.', 'That I should evaporate is my fondest dream', 'What Gilgamesh may do is seek Ishtar', 'You said that Anson thought that Julie had fainted', 'The owl hated the evil bat and the wise eagle', 'What did John buy?', 'Agamemnon forced Aphrodite to leave the school.', 'There is a description of Aristotle in the book.', 'Medea exclaimed if the potion was ready', 'Humans love to eat them.', 'Someone did Medea poison.', 'Perhaps Iphigenia will have murdered Oedipus by tomorrow.', 'So that he could escape, Jason became invisible', 'I wondered who had Medea poisoned.', 'I asked did Medea poison Jason.', 'Agamemnon stopped Jason from casting the spell', 'No one wanted any cake.', 'I wanted Jimmy for to come with me.', 'He walked the hill up.', 'They should have all sent Oedipus to Thebes', 'Those monkey are eating the banana.', 'Who had Poseidon run away, before the executioner murdered?', 'I asked Anson if he was happy', 'Daniel became a blond.', 'Has that we have arrived back at our starting point proved that the world is round?', 'It was the man I saw that you wanted to meet.', \"That photograph by Gomez of Pugsley of Lucy's\", 'I ate that.', 'It snowed', 'Aphrodite said he would free the animals and free the animals he will', 'That the golden thread would show Jason his path through the labyrinth was', 'Julie and Jenny arrived first', 'What have you eaten?', 'Peter is owners.', 'I said this he left', 'Who has drunk my whiskey?', 'You said she liked yourself', 'She tried to left', \"I'd planned to have finished, and finished I have\", 'Ron expected the sack.', 'That I am here proves that I care.', 'She tried to may leave', 'Gilgamesh misses Aphrodite', 'Who seemed had poisoned Jason?', 'That Plato loved Aster seemed to be known by everyone.', 'When dining with evil crocodiles, it is advisable to wear armour.', 'Benjamin said he would give the cloak to Lee and give the cloak he did to Lee.', 'Did the magic work?', 'Who has drunk the poison?', 'Benjamin said he would give the cloak to Lee and give the cloak to Lee he did.', 'Jason became invisible, so that he could escape', 'Aphrodite may quickly free the animals.', 'The horse galloped', 'How quickly did the Greeks take Troy?', 'Some happy pigs which can fly love truffles', 'Julie felt a twinge in her arm', 'The wizard turned the beetle into beer with a wave of his wand', 'Who seemed that had poisoned Jason?', 'Kick me!', 'We wanted to eat cake', \"Gomez's photograph of Pugsley belonging to Lucy.\", 'All the boys should could go', 'Julie maintained her own ideas over the course of the argument.', \"The intrepid pirate and the fearful captain's mate sunk the galleon.\", 'Gilgamesh might not have been reading the cuneiform tablets.', 'It was obvious that Plato loved Aster obvious.', 'He loves him', 'We all thought he was unhappy', 'Emily showed himself Benjamin in the mirror.', 'Anson believed the report.', 'I looked the number up.', 'Anson is incredibly difficult to be pleased.', 'No vampire slept.', 'After the executioner left, Poseidon wept.', 'Peter was at the party', 'Whales have I seen.', 'I thought she is pregnant', 'Himself saw him', 'That he is coming is clear.', 'There seem three men to be in the garden.', 'He analysis her was flawed', 'Where all did they go for their holidays?', 'Gilgamesh decided not to kill Ishtar', 'Bill reading Shakespeare satisfied me', 'Perseus saw the Gorgon in his shield.', 'Poseidon would run away, if the executioner murdered Hera.', 'Who did a statue of surprise Medea?', 'What did you say (that) the poet had written?', 'I saw people playing there on the beach.', 'Who was that Plato loved obvious?', \"I didn't want any cake.\", 'That I should kiss pigs is my fondest dream', 'Gilgamesh flew not the broomstick.', 'Ron failed biology, unfortunately', 'The men chuckle', 'I expected there to be a problem.', 'Gilgamesh wanted to seduce Ishtar, and seduce Ishtar he did .', 'Harry collapsed.', 'I asked who saw what.', 'The doctor arrived a new actor.', 'Him loves him', 'Who had Poseidon run away, because the executioner murdered?', 'He has been happy', 'Poseidon had run away, before the executioner murdered Hera.', 'Which the poem did Homer recite?', 'Not reading of Shakespeare satisfied me', 'Who did Athena introduce who to?', 'Merlin is a dangerous sorcerer.', 'Anson saw Anson.', 'I am to eat macaroni.', 'Poseidon had escaped, before the executioner arrived.', 'Owners love truffles', 'The dragons were slain all.', 'I saw him ever.', 'Humans love to eat owners of pigs.', 'I have sent 0 letter to Environmental Heath', 'What Jason asked whether was the potion was ready', 'Those pigs love truffles', 'We all thought he to be unhappy', \"I'd planned to have finished by now.\", 'Has the potion not worked?', 'What I love is toast and sun dried tomatoes', 'Mary ran.', 'The man I saw shaved myself.', 'Readings Shakespeare satisfied me', 'The picture of no one hung upon any wall.', 'He replied that he was happy.', 'No one could remove the blood from the wall', 'Julie maintained that the barman was sober.', 'I kicked me', 'Benjamin gave Lee the cloak.', 'Aphrodite wanted Hera to persuade Athena to leave.', 'Gilgamesh is fighting the dragon.', 'I claimed she was pregnant', 'For Jenny, I intended to be present.', 'Gilgamesh missed Aphrodite', 'She might be pregnant.', 'The pig grunt', 'Anson demonized David at the club.', 'Jason asked whether the potion was ready', 'Frieda closed the door', 'Peter is the old pigs.', 'Medea might have given Jason a poisoned robe (just treat a poisoned robe as an NP', 'Quickly kiss Anson!', 'Anson believed Jenny to have hurt himself.', 'Julie felt hot', 'Agamemnon expected Esther to seem to be happy.', 'Him book', 'That the answer is obvious upset Hermes.', \"The consul's gift of himself to the gladiator.\", 'Homer recited the poem about Achilles?', 'No vampire can survive sunrise.', 'Under the bed is the best place to hide', 'Anson appeared', 'There seems to be a problem.', 'Anson became that he was happy', 'I intoned that she was happy', 'We all thought him was unhappy', 'Medea saw who?', 'No one expected that Agamemnon would win.', 'Believing that the world is flat gives one some solace.', 'Kick them!', 'The bears sniffs', 'Where did you disappear before you hid the gold?', 'She tried to do go.', 'Medea wondered if the potion was ready', 'Who all did you meet when you were in Derry?', 'Who did you hear an oration about?', 'Alison ran', 'Romeo sent letters to Juliet.', \"Richard's gift of the helicopter to the hospital and of the bus to the school.\", 'Nathan caused Benjamin to see himself in the mirror.', 'a. Madeleine planned to catch the sardines and she did.', 'Medea tried Medea to poison her children.', 'Which temple did Athena contemplate the reason that her devotees had built?', 'I did not understand.', 'Gilgamesh loved Ishtar and Aphrodite did too', 'We believed him to be omnipotent', 'Ron captured quickly a phoenix', 'David ate mangoes and Raffi should too.', \"Julie and Fraser ate those delicious pies in Julie's back garden.\", 'The old pigs love truffles', 'The boys all should could go', 'Aphrodite quickly freed the animals', 'Paul had two affairs', 'What Alison and David did was soak their feet in a bucket', 'Anson demonized David almost constantly.', 'Agamemnon seemed that left.', \"Anson's hen nibbled his ear.\", 'What a kind of actor is he?', 'The constantly reading Shakespeare satisfied me', 'Before the executioner arrived, Poseidon had escaped', \"Gilgamesh didn't leave.\", 'Genie intoned that she was tired', 'Look at all these books. Which book would you like?', 'There were killed three men by the assassin.', 'Peter is those pigs.', \"I don't remember what I said all?\", 'The pig grunts', 'The poison was neutralised was claimed that by everyone', 'People are stupid', 'What I arranged was for Jenny to be present.', 'I compared Ginger to Fred', 'Peter is pigs', 'Which poet wrote which ode?', 'How did Julie ask if Jenny left?', 'Dracula thought him to be the Prince of Darkness.', \"He can't possibly do that, possibly he?\", 'I must eat macaroni.', 'I asked who John would introduce to who.', 'The owl hated the and loved the bat.', 'Reading Shakespeare satisfied me', 'Humans love to eat owners.', 'Gilgamesh fears death and Achilles does as well', 'The pigs grunts', 'Constant reading Shakespeare satisfied me', 'Anson believed to be happy.', 'How did Julie say that Jenny left?', 'Show me letters!', 'The readings of Shakespeare satisfied me', 'Anson demonized David every day.', 'The students demonstrated this morning', 'We believed Aphrodite to be omnipotent.', 'Emily caused Benjamin to see himself in the mirror.', 'Anson left before Jenny saw himself.', 'Nothing like that would I ever eat again.', 'Where has he put the cake?', 'Jason persuaded Medea to desert her family', 'Gilgamesh perhaps should be leaving.', \"Gilgamesh hasn't kissed Ishtar.\", 'Anson thought that himself was going to the club.', 'Poseidon appears to own a dragon', 'Digitize is my happiest memory', 'It is easy to slay the Gorgon.', 'I had the strangest feeling that I knew you.', 'What all did you get for Christmas?']\n",
      "label [1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1]\n",
      "idx [8001, 8002, 8003, 8004, 8005, 8006, 8007, 8008, 8009, 8010, 8011, 8012, 8013, 8014, 8015, 8016, 8017, 8018, 8019, 8020, 8021, 8022, 8023, 8024, 8025, 8026, 8027, 8028, 8029, 8030, 8031, 8032, 8033, 8034, 8035, 8036, 8037, 8038, 8039, 8040, 8041, 8042, 8043, 8044, 8045, 8046, 8047, 8048, 8049, 8050, 8051, 8052, 8053, 8054, 8055, 8056, 8057, 8058, 8059, 8060, 8061, 8062, 8063, 8064, 8065, 8066, 8067, 8068, 8069, 8070, 8071, 8072, 8073, 8074, 8075, 8076, 8077, 8078, 8079, 8080, 8081, 8082, 8083, 8084, 8085, 8086, 8087, 8088, 8089, 8090, 8091, 8092, 8093, 8094, 8095, 8096, 8097, 8098, 8099, 8100, 8101, 8102, 8103, 8104, 8105, 8106, 8107, 8108, 8109, 8110, 8111, 8112, 8113, 8114, 8115, 8116, 8117, 8118, 8119, 8120, 8121, 8122, 8123, 8124, 8125, 8126, 8127, 8128, 8129, 8130, 8131, 8132, 8133, 8134, 8135, 8136, 8137, 8138, 8139, 8140, 8141, 8142, 8143, 8144, 8145, 8146, 8147, 8148, 8149, 8150, 8151, 8152, 8153, 8154, 8155, 8156, 8157, 8158, 8159, 8160, 8161, 8162, 8163, 8164, 8165, 8166, 8167, 8168, 8169, 8170, 8171, 8172, 8173, 8174, 8175, 8176, 8177, 8178, 8179, 8180, 8181, 8182, 8183, 8184, 8185, 8186, 8187, 8188, 8189, 8190, 8191, 8192, 8193, 8194, 8195, 8196, 8197, 8198, 8199, 8200, 8201, 8202, 8203, 8204, 8205, 8206, 8207, 8208, 8209, 8210, 8211, 8212, 8213, 8214, 8215, 8216, 8217, 8218, 8219, 8220, 8221, 8222, 8223, 8224, 8225, 8226, 8227, 8228, 8229, 8230, 8231, 8232, 8233, 8234, 8235, 8236, 8237, 8238, 8239, 8240, 8241, 8242, 8243, 8244, 8245, 8246, 8247, 8248, 8249, 8250, 8251, 8252, 8253, 8254, 8255, 8256, 8257, 8258, 8259, 8260, 8261, 8262, 8263, 8264, 8265, 8266, 8267, 8268, 8269, 8270, 8271, 8272, 8273, 8274, 8275, 8276, 8277, 8278, 8279, 8280, 8281, 8282, 8283, 8284, 8285, 8286, 8287, 8288, 8289, 8290, 8291, 8292, 8293, 8294, 8295, 8296, 8297, 8298, 8299, 8300, 8301, 8302, 8303, 8304, 8305, 8306, 8307, 8308, 8309, 8310, 8311, 8312, 8313, 8314, 8315, 8316, 8317, 8318, 8319, 8320, 8321, 8322, 8323, 8324, 8325, 8326, 8327, 8328, 8329, 8330, 8331, 8332, 8333, 8334, 8335, 8336, 8337, 8338, 8339, 8340, 8341, 8342, 8343, 8344, 8345, 8346, 8347, 8348, 8349, 8350, 8351, 8352, 8353, 8354, 8355, 8356, 8357, 8358, 8359, 8360, 8361, 8362, 8363, 8364, 8365, 8366, 8367, 8368, 8369, 8370, 8371, 8372, 8373, 8374, 8375, 8376, 8377, 8378, 8379, 8380, 8381, 8382, 8383, 8384, 8385, 8386, 8387, 8388, 8389, 8390, 8391, 8392, 8393, 8394, 8395, 8396, 8397, 8398, 8399, 8400, 8401, 8402, 8403, 8404, 8405, 8406, 8407, 8408, 8409, 8410, 8411, 8412, 8413, 8414, 8415, 8416, 8417, 8418, 8419, 8420, 8421, 8422, 8423, 8424, 8425, 8426, 8427, 8428, 8429, 8430, 8431, 8432, 8433, 8434, 8435, 8436, 8437, 8438, 8439, 8440, 8441, 8442, 8443, 8444, 8445, 8446, 8447, 8448, 8449, 8450, 8451, 8452, 8453, 8454, 8455, 8456, 8457, 8458, 8459, 8460, 8461, 8462, 8463, 8464, 8465, 8466, 8467, 8468, 8469, 8470, 8471, 8472, 8473, 8474, 8475, 8476, 8477, 8478, 8479, 8480, 8481, 8482, 8483, 8484, 8485, 8486, 8487, 8488, 8489, 8490, 8491, 8492, 8493, 8494, 8495, 8496, 8497, 8498, 8499, 8500, 8501, 8502, 8503, 8504, 8505, 8506, 8507, 8508, 8509, 8510, 8511, 8512, 8513, 8514, 8515, 8516, 8517, 8518, 8519, 8520, 8521, 8522, 8523, 8524, 8525, 8526, 8527, 8528, 8529, 8530, 8531, 8532, 8533, 8534, 8535, 8536, 8537, 8538, 8539, 8540, 8541, 8542, 8543, 8544, 8545, 8546, 8547, 8548, 8549, 8550]\n"
     ]
    }
   ],
   "source": [
    "for key,val in test_dataset.items():\n",
    "    print(key,val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6c0b2317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "tokenized_data_test = tokenizer(test_dataset[\"sentence\"], return_tensors=\"np\", padding=True)\n",
    "# Tokenizer returns a BatchEncoding, but we convert that to a dict for Keras\n",
    "tokenized_data_test = dict(tokenized_data_test)\n",
    "\n",
    "labels_test = np.array(test_dataset[\"label\"])  # Label is already an array of 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7afbb391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 4s 69ms/step\n",
      "TFSequenceClassifierOutput(loss=None, logits=array([[-0.54708064, -0.38874626],\n",
      "       [-0.7011964 , -0.4900629 ],\n",
      "       [-0.68425846, -0.47410753],\n",
      "       ...,\n",
      "       [-0.78460985, -0.47649327],\n",
      "       [-0.5890778 , -0.43024975],\n",
      "       [-0.6655205 , -0.47994596]], dtype=float32), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(tokenized_data_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c863388b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = np.round_(y_pred[0])\n",
    "y_pred3 = np.argmax(y_pred2, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f43e602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(labels_test, y_pred3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f5264c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
